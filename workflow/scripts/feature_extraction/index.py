import pandas as pd
import click
from damply import dirs
from pathlib import Path

from readii.io.loaders import loadImageDatasetConfig
from readii.utils import logger
from readii.process.config import get_full_data_name


def make_edges_df(mit_index: pd.DataFrame | Path,
                   image_modality: str,
                   mask_modality: str) -> pd.DataFrame:
    """Create rows for matching images and masks from an imgtools autopipeline dataset index file. Each image may have multiple masks, so a row is created for each combination.
    
    Parameters
    ----------
    mit_index : pd.DataFrame | Path
        DataFrame or Path to csv file containing the index data generated by running imgtools autopipeline. Can be from the index.csv or index-simple.csv. Must contain:

        * 'filepath'
        * 'PatientID'
        * 'SampleNumber'
        * 'Modality'
        * 'ImageID'
        * 'SeriesInstanceUID'
        * 'ReferencedSeriesUID'
    image_modality : str
        Modality to filter the index by to get image rows (e.g. CT, MR)
    mask_modality : str
        Modality to filter the index by to get mask rows (e.g. RTSTRUCT, SEG)
            
    Returns
    -------
    edges_df : pd.DataFrame
        DataFrame where each row contains metadata for an image and mask pair. 
    """
    if isinstance(mit_index, Path):
        try:
            # Check that the correct file name has been passed
            assert mit_index.name.endswith("index.csv") or mit_index.name.endswith("index-simple.csv")
            # Load the file into a pandas DataFrame
            mit_index = pd.read_csv(mit_index)

        except AssertionError as e:
            message = "Expected imgtools autopipeline index file ending in 'index.csv' or 'index-simple.csv'."
            logger.error(message)
            raise e
    
    # Get the image rows and mask rows from the MIT index and merge based on 
    #   - mask's ReferencedSeriesUID == image's SeriesInstanceUID
    #   - Matching SampleNumber
    #   - Matching PatientID
    edges_df = pd.merge(
        mit_index[mit_index.Modality == image_modality],
        mit_index[mit_index.Modality == mask_modality],
        left_on=['SeriesInstanceUID', 'SampleNumber', 'PatientID'],
        right_on=['ReferencedSeriesUID', 'SampleNumber', 'PatientID'],
        suffixes=('_image', '_mask')
    )
        
    return edges_df


def generate_pyradiomics_index(dataset_config: dict,
                               mit_index: pd.DataFrame,
                               readii_index: pd.DataFrame | None = None,
                               output_file_path: Path | None = None
                               ) -> pd.DataFrame:
    """Set up and save out index file for PyRadiomics feature extraction. Output file contains columns for ID, Image, and Mask.
    
    Parameters
    ----------
    dataset_config : dict
        Configuration settings for a dataset, loaded with loadImageDatasetConfig
    mit_index : pd.DataFrame
        Dataframe containing metadata for the images and masks processed by imgtools autopipeline.
    readii_index : pd.DataFrame | None
        Dataframe containing metadata for the negative control images processed by make_negative_controls.py using READII
        If not supplied, will set up the index for the original images only.
    output_file_path : Path | None
        File path to save the PyRadiomics index csv out to. If not provided, will be set up as 
        `dirs.PROCDATA / f"{dataset_config['DATA_SOURCE']}_{dataset_name}" / "features" / f"pyradiomics_{dataset_name}_index.csv`

    Returns
    -------
    pyradiomics_index : pd.DataFrame
        Dataframe with columns:

        * SampleID: PatientID + SampleNumber from imgtools autopipeline
        * MaskID: ImageID for the mask, will be the key from the roi_match_map in imgtools autopipeline
        * Permutation - permutation used for READII negative control
        * Region - region used for READII negative control
        * Image - path to the image nifti file
        * Mask - path to the mask nifti file
    """
    dataset_name = dataset_config['DATASET_NAME']

    image_modality = dataset_config["MIT"]["MODALITIES"]["image"]
    mask_modality = dataset_config["MIT"]["MODALITIES"]["mask"]

    mit_edges_index = make_edges_df(mit_index, image_modality, mask_modality)

    # Set up the data from the mit index to point to the original images for feature extraction
    original_images_index = pd.DataFrame(
        data={"SampleID": mit_edges_index.apply(lambda x: f"{x.PatientID}_{str(x.SampleNumber).zfill(4)}", axis=1),
          "MaskID": mit_edges_index['ImageID_mask'],
          "Permutation": "original",
          "Region": "full",
          "Image": mit_edges_index.apply(lambda x: f"{Path(f"mit_{dataset_name}") / x.filepath_image}", axis=1),
          "Mask": mit_edges_index.apply(lambda x: f"{Path(f"mit_{dataset_name}") / x.filepath_mask}", axis=1)
          }
    )

    if readii_index is not None:
        # Set up the data from the readii index to point to the negative control images for feature extraction
        readii_images_index = pd.DataFrame(
            data={"SampleID": readii_index.apply(lambda x: f"{Path(x.dir_original_image).parent}", axis=1),
            "MaskID": readii_index['ImageID_mask'],
            "Permutation": readii_index["Permutation"],
            "Region": readii_index["Region"],
            "Image": readii_index.apply(lambda x: f"{Path(f"readii_{dataset_name}") / x.filepath}", axis=1),
            "Mask": readii_index.apply(lambda x: f"{Path(f"mit_{dataset_name}") / Path(x.dir_original_image).parent / x.dirname_mask / x.ImageID_mask}.nii.gz", axis=1),
            }
        )

        # Concatenate the original and negative control image index dataframes
        pyradiomics_index = pd.concat([original_images_index, readii_images_index], ignore_index=True, axis=0)

        # Sort the resulting index by negative control settings, then SampleID and MaskID
        pyradiomics_index.sort_values(by=['Permutation', 'Region', 'SampleID', 'MaskID', ], inplace=True, ignore_index=True)

    else:
        # No negative control images to process, just use original images index
        pyradiomics_index = original_images_index

    try:
        # If no output file path is provided, use default path setup, which makes a features directory for the dataset and saves the index there
        if output_file_path is None:
            output_file_path = dirs.PROCDATA / f"{dataset_config['DATA_SOURCE']}_{dataset_name}" / "features" / f"pyradiomics_{dataset_name}_index.csv"
        
        # Check that output file path is a .csv
        assert output_file_path.suffix == ".csv"

        # Create any missing parent directories for the output
        output_file_path.parent.mkdir(parents=True, exist_ok=True)

        # Save out the index file
        pyradiomics_index.to_csv(output_file_path, index=False)

        return pyradiomics_index
    
    except AssertionError as e:
        message = f"output_file_path for generate_pyradiomics_index does not end in .csv. Path given: {output_file_path}"
        logger.error(message)
        raise e



@click.command()
@click.option('--dataset', help='Dataset configuration file name (e.g. NSCLC-Radiomics.yaml). Must be in config/datasets.')
@click.option('--method', default='pyradiomics', help='Feature extraction method to use.')
def generate_dataset_index(dataset: str, 
                           method: str = 'pyradiomics'):
    """Create data index file for feature extraction listing image and mask file pairs.
    """
    if dataset is None:
        message = "Dataset name must be provided."
        logger.error(message)
        raise ValueError(message)

    # Load in dataset configuration settings from provided file
    config_dir_path = dirs.CONFIG / 'datasets'
    dataset_config = loadImageDatasetConfig(dataset, config_dir_path)

    dataset_name = dataset_config['DATASET_NAME']
    full_data_name = get_full_data_name(config_dir_path / dataset)
    
    # Construct image directory from DMP and config
    image_directory = dirs.PROCDATA / full_data_name / "images" 

    # Construct output file path from DMP and feature extraction type
    feature_extraction_type = method
    output_file_path = dirs.PROCDATA / full_data_name / "features" / feature_extraction_type / f"{feature_extraction_type}_{dataset_name}_index.csv"
    output_file_path.parent.mkdir(parents=True, exist_ok=True)

    # Load imgtools autopipeline index file
    mit_index_path = image_directory / f'mit_{dataset_name}' / f'mit_{dataset_name}_index-simple.csv'
    if mit_index_path.exists():
        logger.info(f"Loading autopipeline dataset index file: {mit_index_path}")
        mit_index = pd.read_csv(mit_index_path)
    else:
        logger.error(f"No existing index file found at {mit_index_path}. Run imgtools autopipeline first.")
        raise FileNotFoundError()

    # Load READII negative control index file generated by make_negative_controls.py
    readii_index_path = image_directory / f'readii_{dataset_name}' / f'readii_{dataset_name}_index.csv'
    if readii_index_path.exists():
        logger.info(f"Loading readii dataset index file: {readii_index_path}")
        readii_index = pd.read_csv(readii_index_path)
    else:
        logger.warning(f"No existing index file found at {readii_index_path}. No READII negative controls will be processed.")
        readii_index = None

    match feature_extraction_type:
        case "pyradiomics":
            dataset_index = generate_pyradiomics_index(dataset_config,
                                                       mit_index,
                                                       readii_index,
                                                       output_file_path)
        case _:
            message = f"Index generator doesn't exist for {feature_extraction_type}."
            logger.debug(message)
            raise NotImplementedError(message)
    
    return dataset_index



if __name__ == "__main__":
    generate_dataset_index()
    


