import logging
from pathlib import Path
from typing import Optional

import pandas as pd
from damply import dirs
from readii.io.loaders.general import loadFileToDataFrame

# from readii.utils import logger
from readii.process.label import getPatientIdentifierLabel

from readii_2_roqc.utils.settings import get_extraction_index_filepath

logger = logging.getLogger(__name__)

def roi_filter_mask_metadata(mask_metadata:pd.DataFrame,
                             dataset_config:dict
                            ) -> pd.DataFrame:
    """Filter mask metadata dataframe for specific ROI regex from a dataset config file"""
    # Get the metadata rows with the specified ROIs - here for when autopipeline is run with more ROIs set to be extracted than want to be processed with R2R
    roi_regex = dataset_config["MIT"]["ROI_MATCH_MAP"]
    roi_strategy = dataset_config["MIT"]["ROI_STRATEGY"]
    mask_modality = dataset_config["MIT"]["MODALITIES"]["mask"]

    roi_regex_list = roi_regex.split(":")
    roi_key = roi_regex_list[0]
    roi_matches = roi_regex_list[1].strip("'").split(",")

    match roi_strategy:
        case 'MERGE':
            filtered_mask_metadata = mask_metadata[(mask_metadata['ImageID'] == roi_key) & (mask_metadata['Modality'] == mask_modality)] 
        case 'SEPARATE':
            # Get the combined roi key and match in the format generated by autopipeline separate = {roi_key}__{roi_items} with necessary escape characters for regex
            image_id_regex_combos = {rf"{roi_key}__\[{item}\]" for item in roi_matches}
            # Join each combination into a single regex string, separated by | for or
            image_id_regex = r"|".join(image_id_regex_combos)
            # Set a copy of the ImageID column as the index for the filtering function to use
            filtered_mask_metadata = mask_metadata.set_index('ImageID', drop=False)
            # Filter the dataset based on the regex string generated from the ROI Match Map
            filtered_mask_metadata = filtered_mask_metadata.filter(regex=image_id_regex, axis=0)
            # Restore the numeric index
            filtered_mask_metadata = filtered_mask_metadata.reset_index(drop=True)
            filtered_mask_metadata = filtered_mask_metadata[filtered_mask_metadata['Modality'] == mask_modality] 
        case _:
            message = f"The roi strategy {roi_strategy} is not handled by this function. No filtering will be applied."
            logger.info(message)
            filtered_mask_metadata = mask_metadata

    if filtered_mask_metadata.empty:
        message = f"No mask metadata found for {roi_regex} with {roi_strategy} strategy. Try changing input strategy and confirm mask modality ({mask_modality}) is correct."
        logger.error(message)
        raise RuntimeError(message)

    return filtered_mask_metadata



def get_masked_image_metadata(dataset_index:pd.DataFrame,
                              dataset_config:dict,
                              image_modality:Optional[str] = None,
                              mask_modality:Optional[str] = None
                              ) -> pd.DataFrame:
    """Get rows of Med-ImageTools index.csv with the mask modality and the corresponding image modality and create a new index with just these rows for READII
    
    Parameters
    ----------
    dataset_index : pd.DataFrame
        DataFrame loaded from a Med-ImageTools index.csv containing image metadata. Must have columns for Modality, ReferencedSeriesUID, and SeriesInstanceUID.
    dataset_config : dict
        Dictionary of configuration settings to get image and mask modality from for filtering dataset_index. Must include MIT MODALITIES image, mask, ROI_STRATEGY and ROI_MATCH_MAP. Expected output from running loadImageDatasetConfig.
    image_modality : Optional[str]
        Image modality to filter dataset_index with. Will override dataset_config setting.
    mask_modality : Optional[str]
        Mask modality to filter dataset_index with. Will override dataset_config setting.

    Returns
    -------
    pd.DataFrame
        Subset of the dataset_index with just the masks and their reference images' metadata.
    """

    if image_modality is None:
        if dataset_config is None:
            message = "No image modality setting passed. Must pass a image_modality or dataset_config with an image modality setting."
            logger.error(message)
            raise ValueError(message)
        
        # Get the image modality from config to retrieve from the metadata
        image_modality = dataset_config["MIT"]["MODALITIES"]["image"]
    
    if mask_modality is None:
        if dataset_config is None:
            message = "No mask modality setting passed. Must pass a mask_modality or dataset_config with a mask modality setting."
            logger.error(message)
            raise ValueError(message)
        
        # Get the mask modality from config to retrieve from the metadata
        mask_modality = dataset_config["MIT"]["MODALITIES"]["mask"]

    # Create a SampleID to index with
    dataset_index['SampleID'] = dataset_index['PatientID'].astype(str) + "_" + dataset_index['SampleNumber'].astype(str).str.zfill(4)

    # Get all metadata rows with the mask modality
    mask_metadata = dataset_index[dataset_index['Modality'] == mask_modality]
    # Filter the mask metadata by the specified ROIs in the config file
    mask_metadata = roi_filter_mask_metadata(mask_metadata, dataset_config)
    
    # Get image metadata rows with a SeriesInstanceUID matching one of the ReferenceSeriesUIDS of the masks
    image_metadata = dataset_index[dataset_index['Modality'] == image_modality]
    if image_metadata.empty:
        message = f"No image metadata found with Modality == {image_modality}."
        logger.error(message)
        raise RuntimeError(message)

    intersected_samples = pd.Index(mask_metadata['SampleID']).intersection(image_metadata['SampleID'], sort=True)

    # Get the images with the correct ReferencedSeriesUIDs from the masks and the correct SampleIDs
    masked_image_metadata = image_metadata[(image_metadata['SeriesInstanceUID'].isin(mask_metadata['ReferencedSeriesUID'])) & (image_metadata['SampleID'].isin(intersected_samples))]
    if masked_image_metadata.empty:
        message = f"No {image_modality} images in dataset index are referenced by the {mask_modality} masks. Check dataset index for errors or missing data."
        logger.error(message)
        raise RuntimeError(message)
    
    # Return the subsetted metadata
    return pd.concat([masked_image_metadata, mask_metadata], sort=True)



def insert_SampleID(dataset_index:pd.DataFrame) -> pd.DataFrame:
    """Combine the PatientID and SampleNumber columns in an index to generate a SampleID
       SampleNumber is padded with 0s to make a length of four.
    """
    if "SampleID" in dataset_index.columns:
        logger.info("SampleID column already exists in this dataset_index.")
        return dataset_index
    
    if "PatientID" not in dataset_index.columns:
        message = "PatientID column is missing in this dataset_index. Cannot make SampleID."
        logger.error(message)
        raise KeyError(message)
    
    if "SampleNumber" not in dataset_index.columns:
        message = "SampleNumber column is missing in this dataset_index. Cannot make SampleID."
        logger.error(message)
        raise KeyError(message)

    sample_id_series = dataset_index['PatientID'].astype(str) + "_" + dataset_index['SampleNumber'].astype(str).str.zfill(4)
    dataset_index.insert(0, "SampleID", sample_id_series)

    return dataset_index



def insert_r2r_index(dataset_config: dict,
                     data_to_index: pd.DataFrame
                     ) -> pd.DataFrame:
    """Add the Med-ImageTools SampleID index column to a dataframe (e.g. a clinical table) to align with processed imaging data"""
    # Find the existing patient identifier for the data_to_index
    existing_pat_id = getPatientIdentifierLabel(data_to_index)
    extraction_method = f"{dataset_config['EXTRACTION']['METHOD']}"

    # Load the feature extraction index output for the dataset
    full_dataset_name = f"{dataset_config['DATA_SOURCE']}_{dataset_config['DATASET_NAME']}"
    extract_features_dir = dirs.PROCDATA / full_dataset_name / "features" / extraction_method
    r2r_index_path = get_extraction_index_filepath(dataset_config, extract_features_dir)

    if r2r_index_path.exists():
        r2r_index = loadFileToDataFrame(r2r_index_path)
    else:
        message = f"READII {extraction_method} index output don't exist for the {full_dataset_name} dataset. Check that feature extraction ran successfully."
        logger.error(message)
        raise FileNotFoundError(message)

    # Generate a mapping from PatientID to SampleID (PatientID_SampleNumber from Med-ImageTools autopipeline output)
    id_map = r2r_index["SampleID"]
    id_map.index = [id_parts[0] for id_parts in r2r_index["SampleID"].str.split('_')]  # Use the first part of SampleID as the index
    id_map = id_map.drop_duplicates()

    # Apply the map to the dataset to index
    data_to_index['SampleID'] = data_to_index[existing_pat_id].map(id_map)

    return data_to_index



def make_edges_df(mit_index: pd.DataFrame | Path,
                   image_modality: str,
                   mask_modality: str) -> pd.DataFrame:
    """Create rows for matching images and masks from an imgtools autopipeline dataset index file. Each image may have multiple masks, so a row is created for each combination.
    
    Parameters
    ----------
    mit_index : pd.DataFrame | Path
        DataFrame or Path to csv file containing the index data generated by running imgtools autopipeline. Can be from the index.csv or index-simple.csv. Must contain:

        * 'filepath'
        * 'PatientID'
        * 'SampleNumber'
        * 'Modality'
        * 'ImageID'
        * 'SeriesInstanceUID'
        * 'ReferencedSeriesUID'
    image_modality : str
        Modality to filter the index by to get image rows (e.g. CT, MR)
    mask_modality : str
        Modality to filter the index by to get mask rows (e.g. RTSTRUCT, SEG)
            
    Returns
    -------
    edges_df : pd.DataFrame
        DataFrame where each row contains metadata for an image and mask pair. 
    """
    if isinstance(mit_index, Path):
        # Check that the correct file name has been passed
        if not (mit_index.name.endswith("index.csv") or mit_index.name.endswith("index-simple.csv")):
            message = "Expected imgtools autopipeline index file ending in 'index.csv' or 'index-simple.csv'."
            logger.error(message)
            raise ValueError(message)
        # Load the file into a pandas DataFrame
        mit_index = pd.read_csv(mit_index)
    
    # Get the image rows and mask rows from the MIT index and merge based on 
    #   - mask's ReferencedSeriesUID == image's SeriesInstanceUID
    #   - Matching SampleNumber
    #   - Matching PatientID
    edges_df = mit_index[mit_index.Modality == image_modality].merge(
        mit_index[mit_index.Modality == mask_modality],
        left_on=['SeriesInstanceUID', 'SampleNumber', 'PatientID'],
        right_on=['ReferencedSeriesUID', 'SampleNumber', 'PatientID'],
        suffixes=('_image', '_mask')
    )
        
    return edges_df


def remove_slice_index_from_string(img_size:str):
    """Split up 3D image size into a string that looks like original_##_##_n to remove the slice value and add the original part to the front."""

    split_up_img_size_vals = img_size.split('_')
    if len(split_up_img_size_vals) > 1:
        image_size_str = f'original_{"_".join(split_up_img_size_vals[0:2])}_n'
    elif len(split_up_img_size_vals) == 1:
        image_size_str = f'original_{"_".join([split_up_img_size_vals[0], split_up_img_size_vals[0]])}_n'
    else:
        image_size_str = 'original'

    return image_size_str